ğŸ™ï¸ MP3toTranscribe

Local Audio Transcription & AI Summarization (Whisper + Ollama)

MP3toTranscribe is a 100% local, privacy-first application that converts long audio recordingsâ€”meetings, lectures, and interviewsâ€”into accurate transcripts and structured AI summaries.
No cloud services. No API keys. No data leaves your machine.

Built with:
	â€¢	faster-whisper â€“ local speech-to-text
	â€¢	Ollama â€“ local LLM summarization
	â€¢	Streamlit â€“ lightweight web UI

Optimized for Apple Silicon (M1 / M2 / M3).

â¸»

âœ¨ Features
	â€¢	ğŸ§ Upload audio from iPhone Voice Memos (.m4a, .mp3, .wav)
	â€¢	âš¡ Fast local transcription using faster-whisper
	â€¢	ğŸ§  High-quality summaries using Ollama (Llama 3 / Mistral)
	â€¢	ğŸ”’ Fully offline and privacy-safe
	â€¢	ğŸ“¦ Supports large files (up to 500MB / ~8 hours)
	â€¢	ğŸ’° Zero usage cost
	â€¢	ğŸ Tuned for Apple Silicon performance

â¸»

ğŸ—ï¸ Architecture

Audio File
   â†“
faster-whisper (INT8, local)
   â†“
Transcript text
   â†“
Ollama (local LLM)
   â†“
Structured summary


â¸»

ğŸ“‹ Requirements

System
	â€¢	macOS (Apple Silicon recommended)
	â€¢	Python 3.11 or 3.12
	â€¢	Homebrew

System Dependencies

brew install ffmpeg ollama


â¸»

ğŸš€ Setup Instructions

1ï¸âƒ£ Clone the Repository

git clone https://github.com/your-username/MP3toTranscribe.git
cd MP3toTranscribe


â¸»

2ï¸âƒ£ Create & Activate a Virtual Environment

python3 -m venv venv
source venv/bin/activate

You should see (venv) in your terminal.

â¸»

3ï¸âƒ£ Install Python Dependencies

pip install --upgrade pip
pip install -r requirements.txt


â¸»

4ï¸âƒ£ Pull an Ollama Model

ollama pull llama3

Verify Ollama is running:

curl http://localhost:11434

Expected output:

Ollama is running

âš ï¸ If port 11434 is already in use, Ollama is already running â€” this is normal.

â¸»

5ï¸âƒ£ Increase Upload Limit (500MB)

Create the Streamlit config file:

mkdir .streamlit
nano .streamlit/config.toml

Add the following:

[server]
maxUploadSize = 500


â¸»

6ï¸âƒ£ Run the App

streamlit run app.py

Open your browser at:

http://localhost:8501


â¸»

ğŸ§‘â€ğŸ’» How to Use
	1.	Record audio using iPhone Voice Memos
	2.	Share â†’ Save to Files
	3.	Upload the audio file in the app
	4.	Click Transcribe & Summarize
	5.	Review the transcript and AI-generated summary

â¸»

ğŸ§  Summary Prompt Logic

Summaries are generated locally with the following structure:
	â€¢	2â€“3 sentence high-level overview
	â€¢	5â€“8 concise bullet points
	â€¢	Clear, simple language
	â€¢	No filler or repetition
	â€¢	No hallucinated facts

Designed for busy professionals reviewing long conversations.

â¸»

âš¡ Performance (Apple M3)

Audio Length	Time
30 minutes	~4 minutes
1 hour	~8 minutes
Summary	2â€“6 seconds


â¸»

ğŸ“ Project Structure

MP3toTranscribe/
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ venv/
â””â”€â”€ .streamlit/
    â””â”€â”€ config.toml


â¸»

ğŸ› ï¸ Troubleshooting

âŒ Ollama 404 or Connection Error

Ensure Ollama is running:

ollama serve

Or verify:

curl http://localhost:11434


â¸»

âŒ ffmpeg not found

brew install ffmpeg


â¸»

âŒ Slow Performance
	â€¢	Ensure compute_type="int8" is enabled (default)
	â€¢	Close other resource-heavy applications
	â€¢	Use a smaller Whisper model if needed

â¸»

ğŸ” Privacy & Security
	â€¢	No cloud APIs
	â€¢	No external data storage
	â€¢	Audio processed locally and deleted immediately
	â€¢	Safe for confidential meetings and recordings

â¸»

ğŸ—ºï¸ Roadmap (Optional Enhancements)
	â€¢	Auto-chunking for multi-hour files
	â€¢	Per-chunk progress indicators
	â€¢	Export summaries as Markdown / PDF
	â€¢	Batch uploads
	â€¢	Speaker separation (heuristic)
	â€¢	Docker support

â¸»

ğŸ“„ License

MIT License

â¸»

ğŸ™Œ Acknowledgements
	â€¢	OpenAI Whisper (open source)
	â€¢	faster-whisper / CTranslate2
	â€¢	Ollama
	â€¢	Streamlit

â¸»

Want more?

I can also:
	â€¢	Add GitHub badges (Python, license, platform)
	â€¢	Create a Docker-specific README
	â€¢	Split setup into Quick Start vs Advanced
	â€¢	Add screenshots or a demo GIF

Just say the word ğŸ‘
